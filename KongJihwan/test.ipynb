{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T03:01:07.346901Z",
     "start_time": "2025-06-02T03:01:07.180267Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:02:45.430592Z",
     "start_time": "2025-06-02T03:02:43.269513Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -U openpyxl",
   "id": "1ef8ff08baa4e5ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:02:48.387159Z",
     "start_time": "2025-06-02T03:02:47.114713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 복사본 작업\n",
    "# df = commerce_df.copy()\n",
    "df = pd.read_excel('datatata/E_Commerce_Dataset.xlsx',sheet_name=1)\n",
    "\n",
    "# 1. 결축치 처리\n",
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())\n",
    "df['WarehouseToHome'] = df['WarehouseToHome'].fillna(df['WarehouseToHome'].median())\n",
    "df['HourSpendOnApp'] = df['HourSpendOnApp'].fillna(df['HourSpendOnApp'].median())\n",
    "\n",
    "df['NoLastYearPurchase'] = df['OrderAmountHikeFromlastYear'].isna().astype(int)\n",
    "df['OrderAmountHikeFromlastYear'] = df['OrderAmountHikeFromlastYear'].fillna(0)\n",
    "\n",
    "df['CouponUsed'] = df['CouponUsed'].fillna(0)\n",
    "df['OrderCount'] = df['OrderCount'].fillna(0)\n",
    "\n",
    "# NeverOrdered로는 구분하고,\n",
    "# DaySinceLastOrder는 명확히 큰 값 (ex. 최대값 + 1) 으로 채워서 모델이 구분 가능하게끔 설정\n",
    "max_day = df['DaySinceLastOrder'].max()\n",
    "df['DaySinceLastOrder'] = df['DaySinceLastOrder'].fillna(max_day + 1)\n",
    "df['NeverOrdered'] = (df['DaySinceLastOrder'] > max_day).astype(int)\n",
    "\n",
    "# 2. 범주형 인코딩\n",
    "cat_cols = ['PreferredLoginDevice', 'PreferredPaymentMode', 'Gender',\n",
    "            'PreferedOrderCat', 'MaritalStatus']\n",
    "\n",
    "# 나중에 새로운 데이터를 인코딩할때 사용하기 위해서 저장해두기.\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# 3. ID 제거\n",
    "df.drop(columns=['CustomerID'], inplace=True)\n"
   ],
   "id": "a8c6bfacc51ec25b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:02:53.186618Z",
     "start_time": "2025-06-02T03:02:53.154201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# 복사본 생성\n",
    "df1 = df.copy()\n",
    "df2 = df.copy()\n",
    "df3 = df.copy()\n",
    "\n",
    "# 타겟 컬럼 제외한 연속형 수치형 컬럼 추출\n",
    "\n",
    "# 숫자형 컬럼 중에서도 범주형 의미 없는 것만 선택\n",
    "exclude = ['Churn', 'NeverOrdered', 'CityTier', 'PreferredPaymentMode',\n",
    "           'Gender', 'PreferredOrderCat', 'MaritalStatus', 'PreferredLoginDevice']\n",
    "\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.difference(exclude)\n",
    "\n",
    "# 스케일러 정의\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaler_robust = RobustScaler()\n",
    "\n",
    "# 스케일링 적용\n",
    "df1[num_cols] = scaler_standard.fit_transform(df1[num_cols])\n",
    "df2[num_cols] = scaler_minmax.fit_transform(df2[num_cols])\n",
    "df3[num_cols] = scaler_robust.fit_transform(df3[num_cols])"
   ],
   "id": "a333dc327c3cace6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:03:25.468909Z",
     "start_time": "2025-06-02T03:03:25.365953Z"
    }
   },
   "cell_type": "code",
   "source": "df1.to_csv('datatata/finalcsv.csv', index=False)",
   "id": "231ad4372119d266",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
