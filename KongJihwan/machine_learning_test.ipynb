{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T03:10:09.350744Z",
     "start_time": "2025-06-02T03:10:09.162453Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:12:47.044127Z",
     "start_time": "2025-06-02T03:12:47.011620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df = pd.read_csv('datatata/testcsv.csv')\n",
    "df = pd.read_csv('datatata/finalcsv.csv')\n",
    "df.head()"
   ],
   "id": "f442ed5defd10644",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Churn    Tenure  PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
       "0      1 -0.733989                     1         3        -1.146379   \n",
       "1      1 -0.135704                     2         1        -0.906721   \n",
       "2      1 -0.135704                     2         1         1.729519   \n",
       "3      1 -1.212618                     2         3        -0.067917   \n",
       "4      1 -1.212618                     2         1        -0.427405   \n",
       "\n",
       "   PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
       "0                     4       0        0.092654                  -0.67290   \n",
       "1                     6       1        0.092654                   0.30375   \n",
       "2                     4       1       -1.324850                   0.30375   \n",
       "3                     4       1       -1.324850                   0.30375   \n",
       "4                     0       1        0.092654                  -0.67290   \n",
       "\n",
       "   PreferedOrderCat  ...  MaritalStatus  NumberOfAddress  Complain  \\\n",
       "0         -0.261904  ...              2         1.852616  1.584290   \n",
       "1          0.446658  ...              2         1.078430  1.584290   \n",
       "2          0.446658  ...              2         0.691336  1.584290   \n",
       "3         -0.261904  ...              2         1.465523 -0.631198   \n",
       "4          0.446658  ...              2        -0.469944 -0.631198   \n",
       "\n",
       "   OrderAmountHikeFromlastYear  CouponUsed  OrderCount  DaySinceLastOrder  \\\n",
       "0                    -0.811126   -0.355903   -0.636249          -0.180903   \n",
       "1                     0.006426   -0.885990   -0.636249          -0.667565   \n",
       "2                    -0.197962   -0.885990   -0.636249          -0.375568   \n",
       "3                     1.641529   -0.885990   -0.636249          -0.375568   \n",
       "4                    -0.811126   -0.355903   -0.636249          -0.375568   \n",
       "\n",
       "   CashbackAmount  NoLastYearPurchase  NeverOrdered  \n",
       "0       -0.351465           -0.222248             0  \n",
       "1       -1.144715           -0.222248             0  \n",
       "2       -1.157316           -0.222248             0  \n",
       "3       -0.877047           -0.222248             0  \n",
       "4       -0.967895           -0.222248             0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>...</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "      <th>NoLastYearPurchase</th>\n",
       "      <th>NeverOrdered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.733989</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.146379</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092654</td>\n",
       "      <td>-0.67290</td>\n",
       "      <td>-0.261904</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.852616</td>\n",
       "      <td>1.584290</td>\n",
       "      <td>-0.811126</td>\n",
       "      <td>-0.355903</td>\n",
       "      <td>-0.636249</td>\n",
       "      <td>-0.180903</td>\n",
       "      <td>-0.351465</td>\n",
       "      <td>-0.222248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.135704</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.906721</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092654</td>\n",
       "      <td>0.30375</td>\n",
       "      <td>0.446658</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.078430</td>\n",
       "      <td>1.584290</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>-0.885990</td>\n",
       "      <td>-0.636249</td>\n",
       "      <td>-0.667565</td>\n",
       "      <td>-1.144715</td>\n",
       "      <td>-0.222248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.135704</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.729519</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.324850</td>\n",
       "      <td>0.30375</td>\n",
       "      <td>0.446658</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.691336</td>\n",
       "      <td>1.584290</td>\n",
       "      <td>-0.197962</td>\n",
       "      <td>-0.885990</td>\n",
       "      <td>-0.636249</td>\n",
       "      <td>-0.375568</td>\n",
       "      <td>-1.157316</td>\n",
       "      <td>-0.222248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.212618</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.067917</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.324850</td>\n",
       "      <td>0.30375</td>\n",
       "      <td>-0.261904</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.465523</td>\n",
       "      <td>-0.631198</td>\n",
       "      <td>1.641529</td>\n",
       "      <td>-0.885990</td>\n",
       "      <td>-0.636249</td>\n",
       "      <td>-0.375568</td>\n",
       "      <td>-0.877047</td>\n",
       "      <td>-0.222248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.212618</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.427405</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092654</td>\n",
       "      <td>-0.67290</td>\n",
       "      <td>0.446658</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.469944</td>\n",
       "      <td>-0.631198</td>\n",
       "      <td>-0.811126</td>\n",
       "      <td>-0.355903</td>\n",
       "      <td>-0.636249</td>\n",
       "      <td>-0.375568</td>\n",
       "      <td>-0.967895</td>\n",
       "      <td>-0.222248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:10:32.273816Z",
     "start_time": "2025-06-02T03:10:32.264948Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "1acd9b11c3ff286d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Churn', 'Tenure', 'PreferredLoginDevice', 'CityTier',\n",
       "       'WarehouseToHome', 'PreferredPaymentMode', 'Gender', 'HourSpendOnApp',\n",
       "       'NumberOfDeviceRegistered', 'PreferedOrderCat', 'SatisfactionScore',\n",
       "       'MaritalStatus', 'NumberOfAddress', 'Complain',\n",
       "       'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',\n",
       "       'DaySinceLastOrder', 'CashbackAmount', 'NoLastYearPurchase',\n",
       "       'NeverOrdered'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:10:35.320907Z",
     "start_time": "2025-06-02T03:10:35.311313Z"
    }
   },
   "cell_type": "code",
   "source": "df['Churn'].value_counts()  # 불균형",
   "id": "fe5ac51ab87d75db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    4682\n",
       "1     948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:10:37.904942Z",
     "start_time": "2025-06-02T03:10:37.886078Z"
    }
   },
   "cell_type": "code",
   "source": "df.dtypes",
   "id": "b59b8034f691b06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn                            int64\n",
       "Tenure                         float64\n",
       "PreferredLoginDevice             int64\n",
       "CityTier                         int64\n",
       "WarehouseToHome                float64\n",
       "PreferredPaymentMode             int64\n",
       "Gender                           int64\n",
       "HourSpendOnApp                 float64\n",
       "NumberOfDeviceRegistered       float64\n",
       "PreferedOrderCat               float64\n",
       "SatisfactionScore              float64\n",
       "MaritalStatus                    int64\n",
       "NumberOfAddress                float64\n",
       "Complain                       float64\n",
       "OrderAmountHikeFromlastYear    float64\n",
       "CouponUsed                     float64\n",
       "OrderCount                     float64\n",
       "DaySinceLastOrder              float64\n",
       "CashbackAmount                 float64\n",
       "NoLastYearPurchase             float64\n",
       "NeverOrdered                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:10:42.976572Z",
     "start_time": "2025-06-02T03:10:42.969518Z"
    }
   },
   "cell_type": "code",
   "source": "df['MaritalStatus'].value_counts()",
   "id": "af7a569b506c3161",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "1    2986\n",
       "2    1796\n",
       "0     848\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T23:46:54.430347Z",
     "start_time": "2025-06-01T23:46:54.407808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 범주형 컬럼 라벨인코더\n",
    "# 전처리된 데이터는 라벨인코더 사용안해도됨.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['PreferredLoginDevice'] = le.fit_transform(df['PreferredLoginDevice'])\n",
    "df['PreferredPaymentMode'] = le.fit_transform(df['PreferredPaymentMode'])\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['PreferedOrderCat'] = le.fit_transform(df['PreferedOrderCat'])\n",
    "df['MaritalStatus'] = le.fit_transform(df['MaritalStatus'])\n",
    "df.head()"
   ],
   "id": "183c6c9f61c2112b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0  CustomerID  Churn  Tenure  PreferredLoginDevice  CityTier  \\\n",
       "0           0       50001      1     4.0                     1         3   \n",
       "1           3       50004      1     0.0                     2         3   \n",
       "2           5       50006      1     0.0                     0         1   \n",
       "3          11       50012      1    11.0                     1         1   \n",
       "4          12       50013      1     0.0                     2         1   \n",
       "\n",
       "   WarehouseToHome  PreferredPaymentMode  Gender  HourSpendOnApp  ...  \\\n",
       "0              6.0                     4       0             3.0  ...   \n",
       "1             15.0                     4       1             2.0  ...   \n",
       "2             22.0                     4       0             3.0  ...   \n",
       "3              6.0                     4       1             3.0  ...   \n",
       "4             11.0                     1       1             2.0  ...   \n",
       "\n",
       "   PreferedOrderCat  SatisfactionScore  MaritalStatus  NumberOfAddress  \\\n",
       "0                 2                  2              2                9   \n",
       "1                 2                  5              2                8   \n",
       "2                 4                  5              2                2   \n",
       "3                 0                  3              2               10   \n",
       "4                 3                  3              2                2   \n",
       "\n",
       "   Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
       "0         1                         11.0         1.0         1.0   \n",
       "1         0                         23.0         0.0         1.0   \n",
       "2         1                         22.0         4.0         6.0   \n",
       "3         1                         13.0         0.0         1.0   \n",
       "4         1                         13.0         2.0         2.0   \n",
       "\n",
       "   DaySinceLastOrder  CashbackAmount  \n",
       "0                5.0          159.93  \n",
       "1                3.0          134.07  \n",
       "2                7.0          139.19  \n",
       "3                0.0          153.81  \n",
       "4                2.0          134.41  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>...</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50001</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>139.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>50012</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>50013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T23:46:57.159635Z",
     "start_time": "2025-06-01T23:46:57.141623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# .drop 때문에 한 번만 돌려야함\n",
    "byebye = ['Unnamed: 0', 'CustomerID']\n",
    "df.drop(byebye, axis=1, inplace=True)"
   ],
   "id": "c869e3bc1acb04eb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:20.919454Z",
     "start_time": "2025-06-02T03:11:20.888026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "id": "691bef5b9236f457",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T23:59:20.570245Z",
     "start_time": "2025-06-01T23:59:20.552464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 오버샘플링 코드, 오버샘플링 생략 시 실행X\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "id": "98db3ac0d110e720",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T06:19:26.261286Z",
     "start_time": "2025-06-01T06:19:22.613046Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from imbalanced-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Using cached sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Using cached imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Using cached sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   -------------------- ------------------- 1/2 [imbalanced-learn]\n",
      "   ---------------------------------------- 2/2 [imbalanced-learn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "# 위 셀 에러 시 실행\n",
    "%pip install -U imbalanced-learn"
   ],
   "id": "efef2303153d7714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:27.207751Z",
     "start_time": "2025-06-02T03:11:27.091312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 로지스틱 회귀\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter=5000, random_state=42)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print('학습셋 accuracy: ', lr_clf.score(X_train, y_train))\n",
    "print('평가셋 accuracy: ', lr_clf.score(X_test, y_test))"
   ],
   "id": "d62efce6d0e91c32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 accuracy:  0.8794404973357016\n",
      "평가셋 accuracy:  0.8703374777975134\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:29.546341Z",
     "start_time": "2025-06-02T03:11:29.125306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(\n",
    "    kernel='linear',\n",
    "    # kernel='rbf',\n",
    "    gamma='scale',\n",
    "    random_state=42\n",
    ")\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "print('학습셋: ', svc_clf.score(X_train, y_train))\n",
    "print('평가셋: ', svc_clf.score(X_test, y_test))"
   ],
   "id": "ac48fa9e19c7fbe3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋:  0.8805506216696269\n",
      "평가셋:  0.8703374777975134\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:34.413456Z",
     "start_time": "2025-06-02T03:11:31.889493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print('학습셋: ', rf_clf.score(X_train, y_train))\n",
    "print('평가셋: ', rf_clf.score(X_test, y_test))"
   ],
   "id": "f264adbfb9ecad09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋:  0.8938721136767318\n",
      "평가셋:  0.8836589698046181\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T06:27:58.679501Z",
     "start_time": "2025-06-01T06:27:48.144805Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -U xgboost",
   "id": "a6e19c2209364f99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from xgboost) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.1/150.0 MB 16.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 8.9/150.0 MB 22.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 15.2/150.0 MB 24.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 21.0/150.0 MB 25.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 27.0/150.0 MB 26.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 33.3/150.0 MB 26.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 39.3/150.0 MB 27.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 43.0/150.0 MB 26.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 47.7/150.0 MB 25.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 51.6/150.0 MB 25.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 56.6/150.0 MB 25.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 63.4/150.0 MB 25.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 71.0/150.0 MB 26.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 79.7/150.0 MB 27.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 88.3/150.0 MB 28.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 96.2/150.0 MB 29.2 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 105.1/150.0 MB 30.0 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 113.5/150.0 MB 30.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 122.4/150.0 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 130.5/150.0 MB 31.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 138.1/150.0 MB 31.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 145.2/150.0 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 31.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 150.0/150.0 MB 29.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:56.136519Z",
     "start_time": "2025-06-02T03:11:56.124308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n"
   ],
   "id": "abafc1c1c387502",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:11:58.656353Z",
     "start_time": "2025-06-02T03:11:58.216959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    early_stopping_rounds=10,\n",
    "    scale_pos_weight=4  # 오버샘플링 X 시 삭제\n",
    ")\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)], verbose=True)\n",
    "print('학습셋: ', xgb_clf.score(X_train, y_train))\n",
    "print('평가셋: ', xgb_clf.score(X_test, y_test))"
   ],
   "id": "4977972bb5c83ae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.56337\tvalidation_1-logloss:0.57016\n",
      "[1]\tvalidation_0-logloss:0.50829\tvalidation_1-logloss:0.52080\n",
      "[2]\tvalidation_0-logloss:0.46306\tvalidation_1-logloss:0.48060\n",
      "[3]\tvalidation_0-logloss:0.42261\tvalidation_1-logloss:0.44348\n",
      "[4]\tvalidation_0-logloss:0.38715\tvalidation_1-logloss:0.41200\n",
      "[5]\tvalidation_0-logloss:0.35493\tvalidation_1-logloss:0.38215\n",
      "[6]\tvalidation_0-logloss:0.32628\tvalidation_1-logloss:0.35632\n",
      "[7]\tvalidation_0-logloss:0.30056\tvalidation_1-logloss:0.33311\n",
      "[8]\tvalidation_0-logloss:0.27741\tvalidation_1-logloss:0.31280\n",
      "[9]\tvalidation_0-logloss:0.25731\tvalidation_1-logloss:0.29610\n",
      "[10]\tvalidation_0-logloss:0.23911\tvalidation_1-logloss:0.27967\n",
      "[11]\tvalidation_0-logloss:0.22248\tvalidation_1-logloss:0.26569\n",
      "[12]\tvalidation_0-logloss:0.20741\tvalidation_1-logloss:0.25301\n",
      "[13]\tvalidation_0-logloss:0.19330\tvalidation_1-logloss:0.24051\n",
      "[14]\tvalidation_0-logloss:0.18171\tvalidation_1-logloss:0.23059\n",
      "[15]\tvalidation_0-logloss:0.16898\tvalidation_1-logloss:0.22042\n",
      "[16]\tvalidation_0-logloss:0.15789\tvalidation_1-logloss:0.21127\n",
      "[17]\tvalidation_0-logloss:0.14840\tvalidation_1-logloss:0.20342\n",
      "[18]\tvalidation_0-logloss:0.13932\tvalidation_1-logloss:0.19487\n",
      "[19]\tvalidation_0-logloss:0.13096\tvalidation_1-logloss:0.18708\n",
      "[20]\tvalidation_0-logloss:0.12300\tvalidation_1-logloss:0.18074\n",
      "[21]\tvalidation_0-logloss:0.11693\tvalidation_1-logloss:0.17532\n",
      "[22]\tvalidation_0-logloss:0.11114\tvalidation_1-logloss:0.17160\n",
      "[23]\tvalidation_0-logloss:0.10503\tvalidation_1-logloss:0.16703\n",
      "[24]\tvalidation_0-logloss:0.09953\tvalidation_1-logloss:0.16311\n",
      "[25]\tvalidation_0-logloss:0.09482\tvalidation_1-logloss:0.15946\n",
      "[26]\tvalidation_0-logloss:0.09113\tvalidation_1-logloss:0.15716\n",
      "[27]\tvalidation_0-logloss:0.08631\tvalidation_1-logloss:0.15296\n",
      "[28]\tvalidation_0-logloss:0.08286\tvalidation_1-logloss:0.15110\n",
      "[29]\tvalidation_0-logloss:0.07899\tvalidation_1-logloss:0.14834\n",
      "[30]\tvalidation_0-logloss:0.07501\tvalidation_1-logloss:0.14512\n",
      "[31]\tvalidation_0-logloss:0.07184\tvalidation_1-logloss:0.14337\n",
      "[32]\tvalidation_0-logloss:0.06843\tvalidation_1-logloss:0.14048\n",
      "[33]\tvalidation_0-logloss:0.06583\tvalidation_1-logloss:0.13899\n",
      "[34]\tvalidation_0-logloss:0.06312\tvalidation_1-logloss:0.13665\n",
      "[35]\tvalidation_0-logloss:0.06052\tvalidation_1-logloss:0.13501\n",
      "[36]\tvalidation_0-logloss:0.05831\tvalidation_1-logloss:0.13362\n",
      "[37]\tvalidation_0-logloss:0.05607\tvalidation_1-logloss:0.13278\n",
      "[38]\tvalidation_0-logloss:0.05379\tvalidation_1-logloss:0.13114\n",
      "[39]\tvalidation_0-logloss:0.05185\tvalidation_1-logloss:0.12980\n",
      "[40]\tvalidation_0-logloss:0.05007\tvalidation_1-logloss:0.12868\n",
      "[41]\tvalidation_0-logloss:0.04822\tvalidation_1-logloss:0.12727\n",
      "[42]\tvalidation_0-logloss:0.04651\tvalidation_1-logloss:0.12653\n",
      "[43]\tvalidation_0-logloss:0.04475\tvalidation_1-logloss:0.12634\n",
      "[44]\tvalidation_0-logloss:0.04320\tvalidation_1-logloss:0.12482\n",
      "[45]\tvalidation_0-logloss:0.04190\tvalidation_1-logloss:0.12340\n",
      "[46]\tvalidation_0-logloss:0.04021\tvalidation_1-logloss:0.12210\n",
      "[47]\tvalidation_0-logloss:0.03891\tvalidation_1-logloss:0.12213\n",
      "[48]\tvalidation_0-logloss:0.03763\tvalidation_1-logloss:0.12132\n",
      "[49]\tvalidation_0-logloss:0.03623\tvalidation_1-logloss:0.11988\n",
      "[50]\tvalidation_0-logloss:0.03509\tvalidation_1-logloss:0.11978\n",
      "[51]\tvalidation_0-logloss:0.03393\tvalidation_1-logloss:0.11864\n",
      "[52]\tvalidation_0-logloss:0.03299\tvalidation_1-logloss:0.11748\n",
      "[53]\tvalidation_0-logloss:0.03198\tvalidation_1-logloss:0.11698\n",
      "[54]\tvalidation_0-logloss:0.03099\tvalidation_1-logloss:0.11618\n",
      "[55]\tvalidation_0-logloss:0.03020\tvalidation_1-logloss:0.11581\n",
      "[56]\tvalidation_0-logloss:0.02941\tvalidation_1-logloss:0.11622\n",
      "[57]\tvalidation_0-logloss:0.02878\tvalidation_1-logloss:0.11552\n",
      "[58]\tvalidation_0-logloss:0.02797\tvalidation_1-logloss:0.11386\n",
      "[59]\tvalidation_0-logloss:0.02718\tvalidation_1-logloss:0.11324\n",
      "[60]\tvalidation_0-logloss:0.02659\tvalidation_1-logloss:0.11304\n",
      "[61]\tvalidation_0-logloss:0.02593\tvalidation_1-logloss:0.11221\n",
      "[62]\tvalidation_0-logloss:0.02527\tvalidation_1-logloss:0.11185\n",
      "[63]\tvalidation_0-logloss:0.02473\tvalidation_1-logloss:0.11173\n",
      "[64]\tvalidation_0-logloss:0.02412\tvalidation_1-logloss:0.11076\n",
      "[65]\tvalidation_0-logloss:0.02362\tvalidation_1-logloss:0.11108\n",
      "[66]\tvalidation_0-logloss:0.02304\tvalidation_1-logloss:0.11097\n",
      "[67]\tvalidation_0-logloss:0.02255\tvalidation_1-logloss:0.11038\n",
      "[68]\tvalidation_0-logloss:0.02218\tvalidation_1-logloss:0.11025\n",
      "[69]\tvalidation_0-logloss:0.02166\tvalidation_1-logloss:0.10909\n",
      "[70]\tvalidation_0-logloss:0.02121\tvalidation_1-logloss:0.10869\n",
      "[71]\tvalidation_0-logloss:0.02077\tvalidation_1-logloss:0.10827\n",
      "[72]\tvalidation_0-logloss:0.02037\tvalidation_1-logloss:0.10771\n",
      "[73]\tvalidation_0-logloss:0.01997\tvalidation_1-logloss:0.10713\n",
      "[74]\tvalidation_0-logloss:0.01958\tvalidation_1-logloss:0.10628\n",
      "[75]\tvalidation_0-logloss:0.01923\tvalidation_1-logloss:0.10609\n",
      "[76]\tvalidation_0-logloss:0.01882\tvalidation_1-logloss:0.10561\n",
      "[77]\tvalidation_0-logloss:0.01855\tvalidation_1-logloss:0.10536\n",
      "[78]\tvalidation_0-logloss:0.01820\tvalidation_1-logloss:0.10601\n",
      "[79]\tvalidation_0-logloss:0.01781\tvalidation_1-logloss:0.10572\n",
      "[80]\tvalidation_0-logloss:0.01746\tvalidation_1-logloss:0.10546\n",
      "[81]\tvalidation_0-logloss:0.01714\tvalidation_1-logloss:0.10556\n",
      "[82]\tvalidation_0-logloss:0.01693\tvalidation_1-logloss:0.10549\n",
      "[83]\tvalidation_0-logloss:0.01669\tvalidation_1-logloss:0.10514\n",
      "[84]\tvalidation_0-logloss:0.01639\tvalidation_1-logloss:0.10494\n",
      "[85]\tvalidation_0-logloss:0.01612\tvalidation_1-logloss:0.10510\n",
      "[86]\tvalidation_0-logloss:0.01592\tvalidation_1-logloss:0.10457\n",
      "[87]\tvalidation_0-logloss:0.01563\tvalidation_1-logloss:0.10455\n",
      "[88]\tvalidation_0-logloss:0.01536\tvalidation_1-logloss:0.10396\n",
      "[89]\tvalidation_0-logloss:0.01511\tvalidation_1-logloss:0.10429\n",
      "[90]\tvalidation_0-logloss:0.01484\tvalidation_1-logloss:0.10331\n",
      "[91]\tvalidation_0-logloss:0.01462\tvalidation_1-logloss:0.10341\n",
      "[92]\tvalidation_0-logloss:0.01437\tvalidation_1-logloss:0.10282\n",
      "[93]\tvalidation_0-logloss:0.01417\tvalidation_1-logloss:0.10211\n",
      "[94]\tvalidation_0-logloss:0.01394\tvalidation_1-logloss:0.10116\n",
      "[95]\tvalidation_0-logloss:0.01374\tvalidation_1-logloss:0.10136\n",
      "[96]\tvalidation_0-logloss:0.01356\tvalidation_1-logloss:0.10144\n",
      "[97]\tvalidation_0-logloss:0.01335\tvalidation_1-logloss:0.10076\n",
      "[98]\tvalidation_0-logloss:0.01316\tvalidation_1-logloss:0.10099\n",
      "[99]\tvalidation_0-logloss:0.01302\tvalidation_1-logloss:0.10112\n",
      "[100]\tvalidation_0-logloss:0.01287\tvalidation_1-logloss:0.10104\n",
      "[101]\tvalidation_0-logloss:0.01270\tvalidation_1-logloss:0.10081\n",
      "[102]\tvalidation_0-logloss:0.01256\tvalidation_1-logloss:0.10004\n",
      "[103]\tvalidation_0-logloss:0.01241\tvalidation_1-logloss:0.09952\n",
      "[104]\tvalidation_0-logloss:0.01225\tvalidation_1-logloss:0.09976\n",
      "[105]\tvalidation_0-logloss:0.01209\tvalidation_1-logloss:0.09913\n",
      "[106]\tvalidation_0-logloss:0.01193\tvalidation_1-logloss:0.09951\n",
      "[107]\tvalidation_0-logloss:0.01182\tvalidation_1-logloss:0.09926\n",
      "[108]\tvalidation_0-logloss:0.01170\tvalidation_1-logloss:0.09922\n",
      "[109]\tvalidation_0-logloss:0.01154\tvalidation_1-logloss:0.09910\n",
      "[110]\tvalidation_0-logloss:0.01141\tvalidation_1-logloss:0.09876\n",
      "[111]\tvalidation_0-logloss:0.01128\tvalidation_1-logloss:0.09860\n",
      "[112]\tvalidation_0-logloss:0.01118\tvalidation_1-logloss:0.09855\n",
      "[113]\tvalidation_0-logloss:0.01105\tvalidation_1-logloss:0.09820\n",
      "[114]\tvalidation_0-logloss:0.01095\tvalidation_1-logloss:0.09836\n",
      "[115]\tvalidation_0-logloss:0.01085\tvalidation_1-logloss:0.09801\n",
      "[116]\tvalidation_0-logloss:0.01075\tvalidation_1-logloss:0.09840\n",
      "[117]\tvalidation_0-logloss:0.01066\tvalidation_1-logloss:0.09860\n",
      "[118]\tvalidation_0-logloss:0.01055\tvalidation_1-logloss:0.09853\n",
      "[119]\tvalidation_0-logloss:0.01047\tvalidation_1-logloss:0.09848\n",
      "[120]\tvalidation_0-logloss:0.01038\tvalidation_1-logloss:0.09805\n",
      "[121]\tvalidation_0-logloss:0.01026\tvalidation_1-logloss:0.09817\n",
      "[122]\tvalidation_0-logloss:0.01014\tvalidation_1-logloss:0.09790\n",
      "[123]\tvalidation_0-logloss:0.01004\tvalidation_1-logloss:0.09766\n",
      "[124]\tvalidation_0-logloss:0.00994\tvalidation_1-logloss:0.09747\n",
      "[125]\tvalidation_0-logloss:0.00986\tvalidation_1-logloss:0.09780\n",
      "[126]\tvalidation_0-logloss:0.00977\tvalidation_1-logloss:0.09807\n",
      "[127]\tvalidation_0-logloss:0.00968\tvalidation_1-logloss:0.09803\n",
      "[128]\tvalidation_0-logloss:0.00959\tvalidation_1-logloss:0.09809\n",
      "[129]\tvalidation_0-logloss:0.00950\tvalidation_1-logloss:0.09815\n",
      "[130]\tvalidation_0-logloss:0.00941\tvalidation_1-logloss:0.09833\n",
      "[131]\tvalidation_0-logloss:0.00934\tvalidation_1-logloss:0.09870\n",
      "[132]\tvalidation_0-logloss:0.00925\tvalidation_1-logloss:0.09886\n",
      "[133]\tvalidation_0-logloss:0.00916\tvalidation_1-logloss:0.09846\n",
      "학습셋:  0.9964476021314387\n",
      "평가셋:  0.9857904085257548\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T06:31:03.140593Z",
     "start_time": "2025-06-01T06:30:59.946501Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -U lightgbm",
   "id": "23d2a83d9661fecf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from lightgbm) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\play data\\miniconda3\\envs\\ai_basic_env\\lib\\site-packages (from lightgbm) (1.15.3)\n",
      "Using cached lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:12:19.026664Z",
     "start_time": "2025-06-02T03:12:15.805078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n",
    "\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "lgbm_clf.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_names=[\"train\", \"test\"],\n",
    "    eval_metric=\"logloss\",\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=10, verbose=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('학습셋: ', lgbm_clf.score(X_train, y_train))\n",
    "print('평가셋: ', lgbm_clf.score(X_test, y_test))"
   ],
   "id": "9a844e8ac96dba01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 682, number of negative: 3371\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 464\n",
      "[LightGBM] [Info] Number of data points in the train set: 4053, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttrain's binary_logloss: 0.115439\n",
      "학습셋:  0.9937833037300178\n",
      "평가셋:  0.9724689165186501\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:12:24.871988Z",
     "start_time": "2025-06-02T03:12:24.059268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# HistGradientBoosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    validation_fraction=0.2,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=2\n",
    ")\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print('학습셋: ', hgb_clf.score(X_train, y_train))\n",
    "print('평가셋: ', hgb_clf.score(X_test, y_test))"
   ],
   "id": "d1bfad7ca621da7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.001 GB of training data: 0.021 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.40875, val loss: 0.41087, in 0.005s\n",
      "[2/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.37743, val loss: 0.38014, in 0.006s\n",
      "[3/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.35266, val loss: 0.35541, in 0.004s\n",
      "[4/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.33248, val loss: 0.33668, in 0.003s\n",
      "[5/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.31595, val loss: 0.32111, in 0.004s\n",
      "[6/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.30149, val loss: 0.30869, in 0.003s\n",
      "[7/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.28830, val loss: 0.29682, in 0.003s\n",
      "[8/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.27630, val loss: 0.28828, in 0.003s\n",
      "[9/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.26674, val loss: 0.28006, in 0.004s\n",
      "[10/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.25660, val loss: 0.27198, in 0.004s\n",
      "[11/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.24699, val loss: 0.26445, in 0.004s\n",
      "[12/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.23918, val loss: 0.25865, in 0.003s\n",
      "[13/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.23105, val loss: 0.25333, in 0.003s\n",
      "[14/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.22391, val loss: 0.24779, in 0.003s\n",
      "[15/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.21727, val loss: 0.24245, in 0.004s\n",
      "[16/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.21071, val loss: 0.23834, in 0.004s\n",
      "[17/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.20557, val loss: 0.23571, in 0.004s\n",
      "[18/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.20010, val loss: 0.23114, in 0.003s\n",
      "[19/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.19482, val loss: 0.22646, in 0.003s\n",
      "[20/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.19017, val loss: 0.22386, in 0.003s\n",
      "[21/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.18538, val loss: 0.22071, in 0.003s\n",
      "[22/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.18034, val loss: 0.21788, in 0.004s\n",
      "[23/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.17597, val loss: 0.21485, in 0.003s\n",
      "[24/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.17086, val loss: 0.21137, in 0.003s\n",
      "[25/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.16708, val loss: 0.20895, in 0.003s\n",
      "[26/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.16288, val loss: 0.20588, in 0.004s\n",
      "[27/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.15904, val loss: 0.20213, in 0.003s\n",
      "[28/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.15540, val loss: 0.19957, in 0.003s\n",
      "[29/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.15172, val loss: 0.19709, in 0.004s\n",
      "[30/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.14804, val loss: 0.19379, in 0.003s\n",
      "[31/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.14442, val loss: 0.19054, in 0.004s\n",
      "[32/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.14132, val loss: 0.18854, in 0.003s\n",
      "[33/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.13844, val loss: 0.18660, in 0.004s\n",
      "[34/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.13552, val loss: 0.18520, in 0.003s\n",
      "[35/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.13226, val loss: 0.18276, in 0.005s\n",
      "[36/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.12951, val loss: 0.18070, in 0.004s\n",
      "[37/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.12655, val loss: 0.17978, in 0.003s\n",
      "[38/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.12333, val loss: 0.17761, in 0.004s\n",
      "[39/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.12077, val loss: 0.17597, in 0.004s\n",
      "[40/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.11814, val loss: 0.17363, in 0.003s\n",
      "[41/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.11585, val loss: 0.17241, in 0.003s\n",
      "[42/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.11349, val loss: 0.16945, in 0.004s\n",
      "[43/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.11133, val loss: 0.16914, in 0.003s\n",
      "[44/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.10964, val loss: 0.16795, in 0.004s\n",
      "[45/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.10736, val loss: 0.16621, in 0.003s\n",
      "[46/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.10485, val loss: 0.16427, in 0.003s\n",
      "[47/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.10306, val loss: 0.16283, in 0.005s\n",
      "[48/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.10103, val loss: 0.16133, in 0.004s\n",
      "[49/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09911, val loss: 0.15987, in 0.004s\n",
      "[50/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.09714, val loss: 0.15912, in 0.004s\n",
      "[51/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.09518, val loss: 0.15712, in 0.003s\n",
      "[52/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09370, val loss: 0.15586, in 0.002s\n",
      "[53/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.09246, val loss: 0.15510, in 0.003s\n",
      "[54/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.09060, val loss: 0.15382, in 0.004s\n",
      "[55/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.08886, val loss: 0.15224, in 0.005s\n",
      "[56/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.08759, val loss: 0.15141, in 0.004s\n",
      "[57/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.08597, val loss: 0.15023, in 0.003s\n",
      "[58/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.08485, val loss: 0.14944, in 0.006s\n",
      "[59/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.08308, val loss: 0.14799, in 0.003s\n",
      "[60/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08120, val loss: 0.14676, in 0.004s\n",
      "[61/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.08011, val loss: 0.14585, in 0.003s\n",
      "[62/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07825, val loss: 0.14477, in 0.004s\n",
      "[63/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.07678, val loss: 0.14386, in 0.003s\n",
      "[64/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.07529, val loss: 0.14259, in 0.003s\n",
      "[65/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07394, val loss: 0.14139, in 0.004s\n",
      "[66/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.07297, val loss: 0.14036, in 0.004s\n",
      "[67/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.07169, val loss: 0.13929, in 0.004s\n",
      "[68/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.07075, val loss: 0.13842, in 0.004s\n",
      "[69/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06941, val loss: 0.13675, in 0.003s\n",
      "[70/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06811, val loss: 0.13559, in 0.003s\n",
      "[71/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06729, val loss: 0.13481, in 0.002s\n",
      "[72/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06610, val loss: 0.13375, in 0.002s\n",
      "[73/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.06485, val loss: 0.13329, in 0.002s\n",
      "[74/1000] 1 tree, 31 leaves, max depth = 7, train loss: 0.06385, val loss: 0.13282, in 0.003s\n",
      "[75/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06295, val loss: 0.13225, in 0.003s\n",
      "[76/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.06185, val loss: 0.13144, in 0.003s\n",
      "[77/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.06070, val loss: 0.13010, in 0.004s\n",
      "[78/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05995, val loss: 0.12989, in 0.004s\n",
      "[79/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05896, val loss: 0.12901, in 0.003s\n",
      "[80/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05803, val loss: 0.12843, in 0.003s\n",
      "[81/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05714, val loss: 0.12825, in 0.004s\n",
      "[82/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05654, val loss: 0.12787, in 0.003s\n",
      "[83/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.05561, val loss: 0.12732, in 0.004s\n",
      "[84/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.05499, val loss: 0.12658, in 0.003s\n",
      "[85/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05419, val loss: 0.12571, in 0.003s\n",
      "[86/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.05293, val loss: 0.12401, in 0.003s\n",
      "[87/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.05196, val loss: 0.12288, in 0.003s\n",
      "[88/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.05119, val loss: 0.12266, in 0.004s\n",
      "[89/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.05058, val loss: 0.12238, in 0.004s\n",
      "[90/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04992, val loss: 0.12170, in 0.004s\n",
      "[91/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04914, val loss: 0.12071, in 0.003s\n",
      "[92/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.04862, val loss: 0.12046, in 0.003s\n",
      "[93/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04779, val loss: 0.11962, in 0.003s\n",
      "[94/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.04706, val loss: 0.11869, in 0.004s\n",
      "[95/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.04623, val loss: 0.11830, in 0.003s\n",
      "[96/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.04569, val loss: 0.11783, in 0.003s\n",
      "[97/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.04499, val loss: 0.11723, in 0.003s\n",
      "[98/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.04444, val loss: 0.11671, in 0.004s\n",
      "[99/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.04381, val loss: 0.11644, in 0.003s\n",
      "[100/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.04304, val loss: 0.11575, in 0.004s\n",
      "[101/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04222, val loss: 0.11559, in 0.004s\n",
      "[102/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04154, val loss: 0.11523, in 0.003s\n",
      "[103/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04060, val loss: 0.11458, in 0.003s\n",
      "[104/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.04001, val loss: 0.11422, in 0.003s\n",
      "[105/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.03945, val loss: 0.11386, in 0.002s\n",
      "[106/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03892, val loss: 0.11359, in 0.003s\n",
      "[107/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03828, val loss: 0.11282, in 0.003s\n",
      "[108/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03775, val loss: 0.11277, in 0.003s\n",
      "[109/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03724, val loss: 0.11224, in 0.002s\n",
      "[110/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03664, val loss: 0.11165, in 0.003s\n",
      "[111/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03597, val loss: 0.11101, in 0.003s\n",
      "[112/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03554, val loss: 0.11093, in 0.004s\n",
      "[113/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03504, val loss: 0.11018, in 0.003s\n",
      "[114/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03439, val loss: 0.11004, in 0.003s\n",
      "[115/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03392, val loss: 0.10985, in 0.004s\n",
      "[116/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03340, val loss: 0.10975, in 0.003s\n",
      "[117/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03301, val loss: 0.10964, in 0.002s\n",
      "[118/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03267, val loss: 0.10937, in 0.003s\n",
      "[119/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03223, val loss: 0.10905, in 0.003s\n",
      "[120/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03174, val loss: 0.10871, in 0.004s\n",
      "[121/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03132, val loss: 0.10802, in 0.002s\n",
      "[122/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03087, val loss: 0.10759, in 0.003s\n",
      "[123/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03039, val loss: 0.10772, in 0.002s\n",
      "[124/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03010, val loss: 0.10722, in 0.003s\n",
      "[125/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02962, val loss: 0.10647, in 0.003s\n",
      "[126/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02937, val loss: 0.10652, in 0.003s\n",
      "[127/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02899, val loss: 0.10626, in 0.003s\n",
      "[128/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.02841, val loss: 0.10541, in 0.003s\n",
      "[129/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02816, val loss: 0.10537, in 0.003s\n",
      "[130/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02778, val loss: 0.10524, in 0.004s\n",
      "[131/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02721, val loss: 0.10498, in 0.003s\n",
      "[132/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02679, val loss: 0.10420, in 0.003s\n",
      "[133/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02637, val loss: 0.10328, in 0.003s\n",
      "[134/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.02610, val loss: 0.10309, in 0.003s\n",
      "[135/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02563, val loss: 0.10306, in 0.002s\n",
      "[136/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.02541, val loss: 0.10313, in 0.002s\n",
      "[137/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02511, val loss: 0.10290, in 0.002s\n",
      "[138/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02454, val loss: 0.10200, in 0.004s\n",
      "[139/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02413, val loss: 0.10184, in 0.004s\n",
      "[140/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.02360, val loss: 0.10156, in 0.003s\n",
      "[141/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.02328, val loss: 0.10122, in 0.003s\n",
      "[142/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02290, val loss: 0.10069, in 0.003s\n",
      "[143/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.02253, val loss: 0.10048, in 0.003s\n",
      "[144/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.02233, val loss: 0.10004, in 0.003s\n",
      "[145/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02208, val loss: 0.09938, in 0.004s\n",
      "[146/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02171, val loss: 0.09880, in 0.003s\n",
      "[147/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02136, val loss: 0.09866, in 0.004s\n",
      "[148/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.02105, val loss: 0.09835, in 0.004s\n",
      "[149/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.02082, val loss: 0.09815, in 0.016s\n",
      "[150/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.02046, val loss: 0.09802, in 0.003s\n",
      "[151/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.02018, val loss: 0.09766, in 0.002s\n",
      "[152/1000] 1 tree, 31 leaves, max depth = 8, train loss: 0.01993, val loss: 0.09733, in 0.003s\n",
      "[153/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01956, val loss: 0.09689, in 0.003s\n",
      "[154/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.09657, in 0.004s\n",
      "[155/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01905, val loss: 0.09662, in 0.003s\n",
      "[156/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01875, val loss: 0.09691, in 0.003s\n",
      "[157/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01857, val loss: 0.09671, in 0.002s\n",
      "[158/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01832, val loss: 0.09646, in 0.003s\n",
      "[159/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01800, val loss: 0.09619, in 0.003s\n",
      "[160/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01774, val loss: 0.09616, in 0.003s\n",
      "[161/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01756, val loss: 0.09606, in 0.003s\n",
      "[162/1000] 1 tree, 31 leaves, max depth = 14, train loss: 0.01719, val loss: 0.09651, in 0.004s\n",
      "[163/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01698, val loss: 0.09641, in 0.003s\n",
      "[164/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01671, val loss: 0.09591, in 0.003s\n",
      "[165/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.09580, in 0.004s\n",
      "[166/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01638, val loss: 0.09567, in 0.003s\n",
      "[167/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01611, val loss: 0.09495, in 0.004s\n",
      "[168/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01588, val loss: 0.09508, in 0.003s\n",
      "[169/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01564, val loss: 0.09481, in 0.005s\n",
      "[170/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01550, val loss: 0.09472, in 0.003s\n",
      "[171/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.09438, in 0.004s\n",
      "[172/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01509, val loss: 0.09439, in 0.003s\n",
      "[173/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01496, val loss: 0.09447, in 0.005s\n",
      "[174/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01484, val loss: 0.09420, in 0.003s\n",
      "[175/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01458, val loss: 0.09442, in 0.003s\n",
      "[176/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01443, val loss: 0.09423, in 0.003s\n",
      "[177/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01429, val loss: 0.09403, in 0.004s\n",
      "[178/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01411, val loss: 0.09407, in 0.004s\n",
      "[179/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01387, val loss: 0.09396, in 0.003s\n",
      "[180/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01366, val loss: 0.09378, in 0.004s\n",
      "[181/1000] 1 tree, 31 leaves, max depth = 10, train loss: 0.01344, val loss: 0.09381, in 0.003s\n",
      "[182/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01319, val loss: 0.09368, in 0.005s\n",
      "[183/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01298, val loss: 0.09343, in 0.003s\n",
      "[184/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01285, val loss: 0.09356, in 0.003s\n",
      "[185/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01268, val loss: 0.09331, in 0.004s\n",
      "[186/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01248, val loss: 0.09333, in 0.003s\n",
      "[187/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.01238, val loss: 0.09315, in 0.003s\n",
      "[188/1000] 1 tree, 31 leaves, max depth = 15, train loss: 0.01220, val loss: 0.09366, in 0.003s\n",
      "[189/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01196, val loss: 0.09330, in 0.005s\n",
      "[190/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01178, val loss: 0.09359, in 0.002s\n",
      "[191/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01161, val loss: 0.09365, in 0.004s\n",
      "[192/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01144, val loss: 0.09347, in 0.003s\n",
      "[193/1000] 1 tree, 31 leaves, max depth = 11, train loss: 0.01134, val loss: 0.09340, in 0.003s\n",
      "[194/1000] 1 tree, 31 leaves, max depth = 13, train loss: 0.01120, val loss: 0.09331, in 0.002s\n",
      "[195/1000] 1 tree, 31 leaves, max depth = 9, train loss: 0.01109, val loss: 0.09373, in 0.002s\n",
      "[196/1000] 1 tree, 31 leaves, max depth = 16, train loss: 0.01094, val loss: 0.09367, in 0.002s\n",
      "[197/1000] 1 tree, 31 leaves, max depth = 12, train loss: 0.01084, val loss: 0.09371, in 0.003s\n",
      "Fit 197 trees in 0.761 s, (6107 total leaves)\n",
      "Time spent computing histograms: 0.123s\n",
      "Time spent finding best splits:  0.063s\n",
      "Time spent applying splits:      0.106s\n",
      "Time spent predicting:           0.013s\n",
      "학습셋:  0.9933392539964476\n",
      "평가셋:  0.9715808170515098\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T03:12:27.519057Z",
     "start_time": "2025-06-02T03:12:27.492772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그냥 우연히? 평가셋이 점수가 높은?건지?\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "y_pred = lgbm_clf.predict(X_test)\n",
    "y_prob = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 성능 지표\n",
    "print(\"📊 Classification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Non-Churn\", \"Churn\"]))\n",
    "print(\"📉 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"📈 ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ],
   "id": "1767dfe3a31204c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Non-Churn       0.99      0.98      0.98       936\n",
      "       Churn       0.90      0.94      0.92       190\n",
      "\n",
      "    accuracy                           0.97      1126\n",
      "   macro avg       0.95      0.96      0.95      1126\n",
      "weighted avg       0.97      0.97      0.97      1126\n",
      "\n",
      "📉 Confusion Matrix:\n",
      " [[917  19]\n",
      " [ 12 178]]\n",
      "📈 ROC AUC Score: 0.9944613135402609\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
